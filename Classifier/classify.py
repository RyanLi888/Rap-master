"""
åˆ†ç±»å™¨è®­ç»ƒä¸é¢„æµ‹æ¨¡å—
====================

æœ¬æ–‡ä»¶å®ç°äº†æœ€ç»ˆçš„åˆ†ç±»å™¨è®­ç»ƒä¸é¢„æµ‹æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
- å‡†ç¡®ç‡è®¡ç®—
- Co-teaching è®­ç»ƒå¾ªç¯ï¼ˆä¸¤ä¸ªMLPäº’æ•™ï¼‰
- å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹å¹¶ä¿å­˜ç»“æœ
- è¯„ä¼°æŒ‡æ ‡è®¡ç®—ä¸æ¨¡å‹ä¿å­˜

ä½œè€…: RAPIER å¼€å‘å›¢é˜Ÿ
ç‰ˆæœ¬: 1.0
"""

import torch 
import torch.nn as nn
import torch.nn.functional as F

from .model import MLP
import sys, os
import numpy as np
from tqdm import tqdm

from .loss import loss_coteaching

# å¯¼å…¥éšæœºç§å­æ§åˆ¶æ¨¡å—
sys.path.append('../utils')
try:
    from random_seed import deterministic_shuffle, create_deterministic_dataloader, RANDOM_CONFIG
    SEED_CONTROL_AVAILABLE = True
except ImportError:
    SEED_CONTROL_AVAILABLE = False

# è¶…å‚æ•°
batch_size = 128
learning_rate = 1e-3
epochs = 100
num_gradual = 10
forget_rate = 0.1
exponent = 1
rate_schedule = np.ones(epochs) * forget_rate
rate_schedule[:num_gradual] = np.linspace(0, forget_rate ** exponent, num_gradual)

def accuracy(logit, target):
    """
    è®¡ç®—Top-1å‡†ç¡®ç‡
    
    å‚æ•°:
        logit (Tensor): æ¨¡å‹åŸå§‹è¾“å‡º (N, C)
        target (Tensor): çœŸå®æ ‡ç­¾ (N,)
    è¿”å›:
        Tensor: ç™¾åˆ†æ¯”å½¢å¼çš„å‡†ç¡®ç‡
    """
    output = F.softmax(logit, dim=1)
    batch_size = target.size(0)

    _, pred = output.topk(1, 1, True, True)
    pred = pred.t()
    correct = pred.eq(target.view(1, -1).expand_as(pred))

    correct_k = correct[:1].view(-1).float().sum(0, keepdim=True)
    return correct_k.mul_(100.0 / batch_size)

# è®­ç»ƒæ¨¡å‹ï¼ˆCo-teachingï¼‰
def train(train_loader, epoch, model1, optimizer1, model2, optimizer2, device):
    """
    ä½¿ç”¨Co-teachingç­–ç•¥è®­ç»ƒä¸¤ä¸ªæ¨¡å‹
    
    ä¸¤ä¸ªæ¨¡å‹äº’ç›¸é€‰æ‹©å¯¹æ–¹çš„â€œå°æŸå¤±â€æ ·æœ¬è¿›è¡Œæ›´æ–°ï¼Œä»¥é™ä½å™ªå£°æ ‡ç­¾çš„å½±å“ã€‚
    
    å‚æ•°:
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        epoch (int): å½“å‰è½®æ¬¡
        model1, model2: ä¸¤ä¸ªMLPæ¨¡å‹
        optimizer1, optimizer2: å¯¹åº”ä¼˜åŒ–å™¨
        device (int|None): CUDAè®¾å¤‡IDæˆ–None
    è¿”å›:
        tuple(float, float): ä¸¤ä¸ªæ¨¡å‹å„è‡ªçš„è®­ç»ƒå‡†ç¡®ç‡
    """
    
    train_total1=0
    train_correct1=0 
    train_total2=0
    train_correct2=0 

    for i, data_labels in enumerate(train_loader):
        # æ‹†åˆ†ç‰¹å¾ä¸æ ‡ç­¾
        feats = data_labels[:, :-1].to(dtype=torch.float32)
        labels = data_labels[:, -1].to(dtype=int)
        if device != None:
            torch.cuda.set_device(device)
            feats = feats.cuda()
            labels = labels.cuda()
    
        # å‰å‘ä¼ æ’­ä¸å‡†ç¡®ç‡
        logits1 = model1(feats)
        prec1 = accuracy(logits1, labels)
        train_total1 += 1
        train_correct1 += prec1

        logits2 = model2(feats)
        prec2 = accuracy(logits2, labels)
        train_total2 += 1
        train_correct2 += prec2
        
        # Co-teaching æŸå¤±ï¼ˆäº’é€‰å°æŸå¤±æ ·æœ¬ï¼‰
        loss_1, loss_2 = loss_coteaching(logits1, logits2, labels, rate_schedule[epoch])

        optimizer1.zero_grad()
        loss_1.backward()
        optimizer1.step()
        optimizer2.zero_grad()
        loss_2.backward()
        optimizer2.step()

    train_acc1=float(train_correct1)/float(train_total1)
    train_acc2=float(train_correct2)/float(train_total2)
    return train_acc1, train_acc2

# é¢„æµ‹æœªçŸ¥æµé‡æ•°æ®çš„æ ‡ç­¾
def predict(test_loader, model, device, alpha=0.5):
    """
    ç”¨å•ä¸ªæ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹
    
    å‚æ•°:
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        model: è®­ç»ƒå¥½çš„MLPæ¨¡å‹
        device (int|None): CUDAè®¾å¤‡IDæˆ–None
        alpha (float): å°†æ¶æ„æ¦‚ç‡é˜ˆå€¼åŒ–ä¸ºäºŒåˆ†ç±»æ ‡ç­¾çš„é˜ˆå€¼
    è¿”å›:
        np.ndarray: äºŒå€¼é¢„æµ‹ (N,)
    """
    preds = []
    for i, data in enumerate(test_loader):
        # å‰å‘ä¼ æ’­
        feats = data.to(dtype=torch.float32)
        
        if device != None:
            torch.cuda.set_device(device)
            feats = feats.cuda()
        
        logits = model(feats)
        outputs = F.softmax(logits, dim=1)
        preds.append((outputs[:, 1] > alpha).detach().cpu().numpy())

    return np.concatenate(preds, axis=0)

def main(feat_dir, model_dir, result_dir, TRAIN, cuda_device, parallel=5):
    """
    åˆ†ç±»å™¨è®­ç»ƒä¸é¢„æµ‹ä¸»æµç¨‹
    
    1) è¯»å–åŸå§‹ä¸åˆæˆç‰¹å¾å¹¶åˆå¹¶
    2) ä½¿ç”¨Co-teachingè®­ç»ƒä¸¤ä¸ªMLP
    3) ç”¨æ¨¡å‹1åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹å¹¶ä¿å­˜
    4) è®¡ç®—å¹¶ä¿å­˜è¯„ä¼°æŒ‡æ ‡ä¸æ¨¡å‹
    
    å‚æ•°:
        feat_dir (str): ç‰¹å¾ç›®å½•
        model_dir (str): æ¨¡å‹ä¿å­˜ç›®å½•
        result_dir (str): ç»“æœä¿å­˜ç›®å½•
        TRAIN (str): è®­ç»ƒæ•°æ®æ ‡ç­¾å‰ç¼€
        cuda_device (int|str): CUDAè®¾å¤‡ID
        parallel (int): å¹¶è¡Œç”Ÿæˆçš„ä»½æ•°ï¼Œç”¨äºæ‹¼æ¥ç”Ÿæˆæ•°æ®
    """
    
    cuda_device = int(cuda_device)
    # è¯»å–åŸå§‹è®­ç»ƒé›†ï¼ˆä»…å‰32ç»´ç‰¹å¾ï¼‰
    be = np.load(os.path.join(feat_dir, 'be_corrected.npy'))[:, :32]
    ma = np.load(os.path.join(feat_dir, 'ma_corrected.npy'))[:, :32]
    be_shape = be.shape[0]
    ma_shape = ma.shape[0]

    # æ‹¼æ¥å¹¶éšæœºæŠ½å–åˆæˆæ ·æœ¬å¢å¼ºè®­ç»ƒé›†
    for index in range(parallel):
        # åŠ è½½åˆæˆç‰¹å¾
        be_gen = np.load(os.path.join(feat_dir, 'be_%s_generated_GAN_%d.npy' % (TRAIN, index)))
        ma_gen1 = np.load(os.path.join(feat_dir, 'ma_%s_generated_GAN_1_%d.npy' % (TRAIN, index)))
        ma_gen2 = np.load(os.path.join(feat_dir, 'ma_%s_generated_GAN_2_%d.npy' % (TRAIN, index)))
        
        # ä½¿ç”¨ç¡®å®šæ€§æ‰“ä¹±
        if SEED_CONTROL_AVAILABLE:
            be_gen = deterministic_shuffle(be_gen, seed=RANDOM_CONFIG['classifier_seed'] + index)
            ma_gen1 = deterministic_shuffle(ma_gen1, seed=RANDOM_CONFIG['classifier_seed'] + index + 1000)
            ma_gen2 = deterministic_shuffle(ma_gen2, seed=RANDOM_CONFIG['classifier_seed'] + index + 2000)
            if index == 0:
                print("âœ… åˆ†ç±»å™¨: ä½¿ç”¨ç¡®å®šæ€§æ•°æ®æ‰“ä¹±")
        else:
            np.random.shuffle(be_gen)
            np.random.shuffle(ma_gen1)
            np.random.shuffle(ma_gen2)
            if index == 0:
                print("âš ï¸  åˆ†ç±»å™¨: ä½¿ç”¨éç¡®å®šæ€§æ•°æ®æ‰“ä¹±")
        be = np.concatenate([
            be, 
            be_gen[:be_shape // (parallel)], 
        ], axis=0)
        
        ma = np.concatenate([
            ma,
            ma_gen1[:ma_shape // (parallel) // 5],
            ma_gen2[:ma_shape // (parallel) // 5],
        ], axis=0)

    print(be.shape, ma.shape)

    # ç»„è£…è®­ç»ƒé›†
    train_data = np.concatenate([be, ma], axis=0)
    train_label = np.concatenate([np.zeros(be.shape[0]), np.ones(ma.shape[0])], axis=0)
    train_dataset = np.concatenate((train_data, train_label[:, None]), axis=1)

    # è¯»å–æµ‹è¯•é›†
    test_data_label = np.load(os.path.join(feat_dir, 'test.npy'))
    test_data = test_data_label[:, :32]
    test_label = test_data_label[:, -1]

    device = int(cuda_device) if cuda_device != 'None' else None

    if device != None:
        torch.cuda.set_device(device)
    # æ•°æ®åŠ è½½å™¨
    print('loading dataset...')
    if SEED_CONTROL_AVAILABLE:
        train_loader = create_deterministic_dataloader(train_dataset, batch_size, shuffle=True, seed=RANDOM_CONFIG['classifier_seed'])
        print("âœ… åˆ†ç±»å™¨: ä½¿ç”¨ç¡®å®šæ€§æ•°æ®åŠ è½½å™¨")
    else:
        train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
        print("âš ï¸  åˆ†ç±»å™¨: ä½¿ç”¨éç¡®å®šæ€§æ•°æ®åŠ è½½å™¨")
    # å®šä¹‰ä¸¤ä¸ªMLPæ¨¡å‹ä¸ä¼˜åŒ–å™¨
    print('building model...')
    mlp1 = MLP(input_size=32, hiddens=[16, 8], output_size=2, device=device)
    if device != None:
        mlp1.to_cuda(device)
        mlp1 = mlp1.cuda()
    optimizer1 = torch.optim.Adam(mlp1.parameters(), lr=learning_rate)
    
    mlp2 = MLP(input_size=32, hiddens=[16, 8], output_size=2, device=device)
    if device != None:
        mlp2.to_cuda(device)
        mlp2 = mlp2.cuda()
    optimizer2 = torch.optim.Adam(mlp2.parameters(), lr=learning_rate)

    # è®­ç»ƒ
    epoch=0
    mlp1.train()
    mlp2.train()
    for epoch in tqdm(range(epochs)):
        train(train_loader, epoch, mlp1, optimizer1, mlp2, optimizer2, device)
    
    # æµ‹è¯•ä¸ä¿å­˜é¢„æµ‹
    mlp1.eval()
    test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)
    preds = predict(test_loader, mlp1, device)
    np.save(os.path.join(result_dir, 'prediction.npy'), preds)

    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    scores = np.zeros((2, 2))
    for label, pred in zip(test_label, preds):
        scores[int(label), int(pred)] += 1
    TP = scores[1, 1]
    FP = scores[0, 1]
    TN = scores[0, 0]
    FN = scores[1, 0]
    
    Accuracy = (TP + TN) / (TP + TN + FP + FN)
    Recall = TP / (TP + FN)
    Precision = TP / (TP + FP)
    F1score = 2 * Recall * Precision / (Recall + Precision)
    print(Recall, Precision, F1score)
    
    with open('../data/result/detection_result.txt', 'w') as fp:
        fp.write('Testing data: Benign/Malicious = %d/%d\n'%((TN + FP), (TP + FN)))
        fp.write('Recall: %.2f, Precision: %.2f, F1: %.2f\n'%(Recall, Precision, F1score))
        fp.write('Acc: %.2f\n'%(Accuracy))

    # ä¿å­˜æ¨¡å‹
    mlp1 = mlp1.cpu()
    mlp1.to_cpu()
    torch.save(mlp1, os.path.join(model_dir, 'Detection_Model.pkl'))

def predict_only(feat_dir, model_dir, result_dir, TRAIN, cuda_device, parallel=5):
    """
    ä»…è¿›è¡Œé¢„æµ‹çš„åˆ†ç±»å™¨å‡½æ•°ï¼ˆä¸é‡æ–°è®­ç»ƒï¼‰
    
    è¯¥å‡½æ•°åŠ è½½å·²è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œç›´æ¥åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹ï¼Œé€‚ç”¨äºä½¿ç”¨æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆé¢„æµ‹çš„åœºæ™¯ã€‚
    
    å‚æ•°:
        feat_dir (str): ç‰¹å¾ç›®å½•
        model_dir (str): æ¨¡å‹ä¿å­˜ç›®å½•ï¼ˆåŒ…å« Detection_Model.pklï¼‰
        result_dir (str): ç»“æœä¿å­˜ç›®å½•
        TRAIN (str): è®­ç»ƒæ•°æ®æ ‡ç­¾å‰ç¼€ï¼ˆè™½ç„¶ä¸è®­ç»ƒï¼Œä½†ç”¨äºç¡®å®šæ•°æ®æ ¼å¼ï¼‰
        cuda_device (int|str): CUDAè®¾å¤‡ID
        parallel (int): å¹¶è¡Œç”Ÿæˆçš„ä»½æ•°ï¼ˆç”¨äºæ•°æ®æ ¼å¼å…¼å®¹ï¼‰
    """
    
    cuda_device = int(cuda_device)
    device = int(cuda_device) if cuda_device != 'None' else None
    
    # åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹
    model_path = os.path.join(model_dir, 'Detection_Model.pkl')
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°å·²è®­ç»ƒçš„æ¨¡å‹æ–‡ä»¶ {model_path}")
        return
    
    print(f"ğŸ“‚ åŠ è½½å·²è®­ç»ƒçš„åˆ†ç±»å™¨æ¨¡å‹: {model_path}")
    mlp1 = torch.load(model_path)
    
    if device != None:
        torch.cuda.set_device(device)
        mlp1 = mlp1.cuda()
    
    # è¯»å–æµ‹è¯•é›†
    test_data_label = np.load(os.path.join(feat_dir, 'test.npy'))
    test_data = test_data_label[:, :32]
    test_label = test_data_label[:, -1]
    
    print(f"ğŸ” å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹ (æµ‹è¯•æ ·æœ¬æ•°: {len(test_data)})")
    
    # æµ‹è¯•ä¸ä¿å­˜é¢„æµ‹
    mlp1.eval()
    test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)
    preds = predict(test_loader, mlp1, device)
    
    # ä¿å­˜é¢„æµ‹ç»“æœ
    prediction_file = os.path.join(result_dir, 'prediction.npy')
    np.save(prediction_file, preds)
    print(f"ğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {prediction_file}")
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    scores = np.zeros((2, 2))
    for label, pred in zip(test_label, preds):
        scores[int(label), int(pred)] += 1
    TP = scores[1, 1]
    FP = scores[0, 1]
    TN = scores[0, 0]
    FN = scores[1, 0]
    
    Accuracy = (TP + TN) / (TP + TN + FP + FN)
    Recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0
    Precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0
    F1score = 2 * Recall * Precision / (Recall + Precision) if (Recall + Precision) > 0 else 0.0
    
    print(f"ğŸ“Š æœ€ç»ˆé¢„æµ‹ç»“æœ:")
    print(f"   å‡†ç¡®ç‡: {Accuracy:.4f}")
    print(f"   å¬å›ç‡: {Recall:.4f}")  
    print(f"   ç²¾ç¡®ç‡: {Precision:.4f}")
    print(f"   F1åˆ†æ•°: {F1score:.4f}")
    
    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    result_file = os.path.join(result_dir, 'final_detection_result.txt')
    with open(result_file, 'w') as fp:
        fp.write('=== æœ€ç»ˆé¢„æµ‹ç»“æœï¼ˆä½¿ç”¨æœ€ä½³æ¨¡å‹ï¼‰ ===\n')
        fp.write('Testing data: Benign/Malicious = %d/%d\n'%((TN + FP), (TP + FN)))
        fp.write('Recall: %.4f, Precision: %.4f, F1: %.4f\n'%(Recall, Precision, F1score))
        fp.write('Accuracy: %.4f\n'%(Accuracy))
    
    print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    return F1score

def predict_only_from_file(feat_dir, model_file_path, result_dir, TRAIN, cuda_device, parallel=5):
    """
    ä»æŒ‡å®šçš„æ¨¡å‹æ–‡ä»¶è¿›è¡Œé¢„æµ‹ï¼ˆä¸é‡æ–°è®­ç»ƒï¼‰
    
    è¯¥å‡½æ•°ä»æŒ‡å®šçš„æ¨¡å‹æ–‡ä»¶åŠ è½½æ¨¡å‹ï¼Œç›´æ¥åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹ã€‚
    ä¸“é—¨ç”¨äºåŠ è½½æœ€ä½³æ¨¡å‹æ–‡ä»¶è¿›è¡Œæœ€ç»ˆé¢„æµ‹ã€‚
    
    å‚æ•°:
        feat_dir (str): ç‰¹å¾ç›®å½•
        model_file_path (str): æ¨¡å‹æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        result_dir (str): ç»“æœä¿å­˜ç›®å½•
        TRAIN (str): è®­ç»ƒæ•°æ®æ ‡ç­¾å‰ç¼€
        cuda_device (int|str): CUDAè®¾å¤‡ID
        parallel (int): å¹¶è¡Œç”Ÿæˆçš„ä»½æ•°
        
    è¿”å›:
        float: F1åˆ†æ•°
    """
    
    cuda_device = int(cuda_device)
    device = int(cuda_device) if cuda_device != 'None' else None
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_file_path):
        print(f"âŒ é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {model_file_path}")
        return 0.0
    
    print(f"ğŸ“‚ ä»æŒ‡å®šæ–‡ä»¶åŠ è½½æœ€ä½³åˆ†ç±»å™¨æ¨¡å‹: {model_file_path}")
    
    try:
        # åŠ è½½æ¨¡å‹
        mlp1 = torch.load(model_file_path)
        
        if device != None:
            torch.cuda.set_device(device)
            mlp1 = mlp1.cuda()
        
        # è¯»å–æµ‹è¯•é›†
        test_data_label = np.load(os.path.join(feat_dir, 'test.npy'))
        test_data = test_data_label[:, :32]
        test_label = test_data_label[:, -1]
        
        print(f"ğŸ” ä½¿ç”¨æœ€ä½³æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹ (æµ‹è¯•æ ·æœ¬æ•°: {len(test_data)})")
        
        # æµ‹è¯•ä¸ä¿å­˜é¢„æµ‹
        mlp1.eval()
        test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)
        preds = predict(test_loader, mlp1, device)
        
        # ä¿å­˜é¢„æµ‹ç»“æœ
        prediction_file = os.path.join(result_dir, 'best_model_prediction.npy')
        np.save(prediction_file, preds)
        print(f"ğŸ’¾ æœ€ä½³æ¨¡å‹é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {prediction_file}")
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        scores = np.zeros((2, 2))
        for label, pred in zip(test_label, preds):
            scores[int(label), int(pred)] += 1
        TP = scores[1, 1]
        FP = scores[0, 1]
        TN = scores[0, 0]
        FN = scores[1, 0]
        
        Accuracy = (TP + TN) / (TP + TN + FP + FN)
        Recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0
        Precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0
        F1score = 2 * Recall * Precision / (Recall + Precision) if (Recall + Precision) > 0 else 0.0
        
        print(f"ğŸ“Š æœ€ä½³æ¨¡å‹é¢„æµ‹ç»“æœ:")
        print(f"   å‡†ç¡®ç‡: {Accuracy:.4f}")
        print(f"   å¬å›ç‡: {Recall:.4f}")  
        print(f"   ç²¾ç¡®ç‡: {Precision:.4f}")
        print(f"   F1åˆ†æ•°: {F1score:.4f}")
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        result_file = os.path.join(result_dir, 'best_model_final_result.txt')
        with open(result_file, 'w') as fp:
            fp.write('=== æœ€ä½³æ¨¡å‹æœ€ç»ˆé¢„æµ‹ç»“æœ ===\n')
            fp.write(f'ä½¿ç”¨çš„æ¨¡å‹æ–‡ä»¶: {model_file_path}\n')
            fp.write('Testing data: Benign/Malicious = %d/%d\n'%((TN + FP), (TP + FN)))
            fp.write('Recall: %.4f, Precision: %.4f, F1: %.4f\n'%(Recall, Precision, F1score))
            fp.write('Accuracy: %.4f\n'%(Accuracy))
        
        print(f"ğŸ“„ æœ€ä½³æ¨¡å‹è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
        
        return F1score
        
    except Exception as e:
        print(f"âŒ ä»æ–‡ä»¶åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return 0.0

